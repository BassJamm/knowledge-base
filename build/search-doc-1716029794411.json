{"searchDocs":[{"title":"Backing up Resources in Azure","type":0,"sectionRef":"#","url":"/blog/Backing-up-resources-with-AzBackup","content":"","keywords":"","version":null},{"title":"Before you dive in​","type":1,"pageTitle":"Backing up Resources in Azure","url":"/blog/Backing-up-resources-with-AzBackup#before-you-dive-in","content":" Some decisions to consider before clicking about and winging it:  Policy Naming Conventions.How are you going to group your resources? (Don't care or different policies per resource type?)Backup Schedules.Alerting.  You'll need to setup the following:  A resource Group.Service Recovery Services Vault.Log Analytics Workspace.  ","version":null,"tagName":"h2"},{"title":"The Run down​","type":1,"pageTitle":"Backing up Resources in Azure","url":"/blog/Backing-up-resources-with-AzBackup#the-run-down","content":" info Use whatever naming conention fits in with what’s being used already, I am just suggesting something here.  Below sections outline my steps for setting up Azure Backup.  ","version":null,"tagName":"h2"},{"title":"Creating the Resources​","type":1,"pageTitle":"Backing up Resources in Azure","url":"/blog/Backing-up-resources-with-AzBackup#creating-the-resources","content":" Create the resource group, for example, rg-customername-region-prod/dev-backups-01.Create a recovery services vault to store the backups (GRS is the preferred option, LRS for lowest cost), for example, rsv-customername-region-prod/dev-backup-01.Create a log analytics workspace or reuse another one, for example, la-customername-region-prod/dev-backup-01.  ","version":null,"tagName":"h3"},{"title":"Configure Backup Policy​","type":1,"pageTitle":"Backing up Resources in Azure","url":"/blog/Backing-up-resources-with-AzBackup#configure-backup-policy","content":" Configure the backup policy in-line with whatever standard is being used already, my suggestions are below.  In the Azure portal, select a Recovery Services vault to back up the VM.Under Backup, select Backup Policies.Click +Add.On Select policy type, select Azure Virtual Machine.On Create policy, perform the following actions:Policy sub type: StandardSuggested Name format: Bkup-policy-time of day-policy type (example name: bkup-policy-nightly-std).  ","version":null,"tagName":"h3"},{"title":"Configure Alerting​","type":1,"pageTitle":"Backing up Resources in Azure","url":"/blog/Backing-up-resources-with-AzBackup#configure-alerting","content":" tip Note that this method is using the old backup alerting method, this is being replaced by Azure Monitor.  Microsoft Link for more information  Configure diagnostic logs to be sent from Azure Backup to the Log Anlytics workspace above.  From the Recovery services vault just setup.Click on Backup Alerts, under the Monitoring section.Click Configure Notifications.Enable Notifications: YesRecipients(Email): 'monitoring@DomainName.com'Notify: Hourly digestSeverity: Critical &amp; Warning  ","version":null,"tagName":"h3"},{"title":"Configure Diagnostic log collection​","type":1,"pageTitle":"Backing up Resources in Azure","url":"/blog/Backing-up-resources-with-AzBackup#configure-diagnostic-log-collection","content":" Configure diagnostic logs to be sent from Azure Backup to the Log Anlytics workspace above.  Navigate to Diagnostic settings under Monitoring.Click Add Diagnostic Settings.Name your diagnostic setting, something informational, for example, “AzBkup-Diagnostics”, suggestion, Backup Report Data.Select Send to Log Analytics Workspace.Add a workspace and don’t touch any other settings.Hit Save.  tip Make sure to run the initial backup job from the Azure Backup Dashboard. ","version":null,"tagName":"h3"},{"title":"Automate Scripts in Azure","type":0,"sectionRef":"#","url":"/blog/Automate-scripts-in-Azure","content":"","keywords":"","version":null},{"title":"What's my goal for this?​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#whats-my-goal-for-this","content":" My situation is this: I frequently receive requests to generate reports from Azure AD and Intune (Endpoint Manager). These requests occur on a monthly or, in some cases, a weekly basis, especially when there's an ongoing issue being troublshooted that impacts the reporting.  Each time I get a report request, I have to log into the environment, execute my script, and send the report via email to the same suspects. While this process may not seem overly burdensome, the scripts are on my machine (archaic I know), I wrote them and I think, that noone else should have to be running them manually!  To simplify this, I aim to automate the scripts on a monthly schedule and retain the flexibility to run them whenever needed.  The Information from here on out. All of the informaiton below is from my setting this up for the 1st time and noting down what I have done and any issues I come across. If you want best practices etc, check out the Microsoft docs.  ","version":null,"tagName":"h2"},{"title":"Outline​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#outline","content":" Run As accounts deprecation Run As accounts are being deprecated, managed identities are replacing this.  Setup the Resource Group and Automation Account.Setup the Identity for the Automation Account, this is key to running scripts gainst Azure Active Directoy and Office 365 resources.Create ourselves a Runbook, that sits inside the Automation Account.Install the relevant modules for the code we want to run.Write ourselves a little script.Setup a schedule for the Runbook.  ","version":null,"tagName":"h2"},{"title":"Setup the Resource Group and Automation Account​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#setup-the-resource-group-and-automation-account","content":" Assumption of you &quot;knowing what you are doing&quot; I (maybe wrongly so) am assuming you have setup Azure resources before and know the basics of this process.  Before you charge into this part.  Make sure you Select the same region as the resources you want to query, if the account is to query something else, like Azure AD or Office 365, the region is not so important. Also, have a good idea what your security requirments are for the Automation Account.  Setup the Automation Account:  Navigate to the Azure portal.Search for Automation Account in the search bar.Select the Automation Account option, Click create in the middle of the screen or Click +Add in the top left.Fill in the necessary information.  When you Select the Advanced Tab Here you can decide whether you want to use a System assigned or User Assigned Identity. Long story short, the System Assigned Identity can only be used by this one Automation Account, the User Assigned Identity can be used by multiple resources.  ","version":null,"tagName":"h2"},{"title":"Apply permissions to Managed(System assigned) Identity​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#apply-permissions-to-managedsystem-assigned-identity","content":" You'll need to apply the permissions to the Managed Identity using PowerShell unfortunatly, a Microsoft seem to have decided to make this difficult for us!  Reference for where this came fromMicrosoft reference for command.  Role names You'll need to find the correct role\\permission name that you want to assign using the script below. Try this Microsoft doc for the Microosft Graph API permissions.  ","version":null,"tagName":"h2"},{"title":"The command​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#the-command","content":" The below is a script you can run but, you can run it line by line to see what is going on if that's more comfortable. The general gist is that you are applying the permissions from the Microsoft Graph App to your Managed Identity.  Annotated the hell out of it as the script logic really confused me.  Heads up! It takes a few minutes for this change to show in the GUI.If the permission already exists the prompt will error on the final command.   # Your tenant id. $TenantID=&quot;Add your tenant ID&quot; # Microsoft Graph App ID (DON'T CHANGE). $GraphAppId = &quot;00000003-0000-0000-c000-000000000000&quot; # Name of the manage identity (same as the Logic App name). $DisplayNameOfMSI=&quot;Add display name of Enterprise App&quot; # Check the Microsoft Graph documentation for the permission you need for the operation. $PermissionName = &quot;Add your permission here&quot; # Install the module (You need admin on the machine) Install-Module AzureAD # Connect to Azure AD via tenant ID, you'll need an admin account to login with though. Connect-AzureAD -TenantId $TenantID # Collects the Target System Managed Identities information into the MSI variable. $MSI = (Get-AzureADServicePrincipal -Filter &quot;displayName eq '$DisplayNameOfMSI'&quot;) Start-Sleep -Seconds 10 # Store the Microsoft Graph API informaiton into the GraphServicePrincipal variable. $GraphServicePrincipal = Get-AzureADServicePrincipal -Filter &quot;appId eq '$GraphAppId'&quot; # Searches Microsoft Graph API for the value matching the PermissionName variable populated above and stores this in the AppRole Variable. $AppRole = $GraphServicePrincipal.AppRoles | Where-Object {$_.Value -eq $PermissionName -and $_.AllowedMemberTypes -contains &quot;Application&quot;} # Assigned the permission from the Microsoft Graph API to the target Managed Identity. New-AzureADServiceAppRoleAssignment -ObjectId $MSI.ObjectId -ResourceId $GraphServicePrincipal.ObjectId -Id $appRole.Id -PrincipalId $MSI.ObjectId   ","version":null,"tagName":"h2"},{"title":"Setup Automation Runbook​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#setup-automation-runbook","content":" The Runbook is the container if you like for your script and anything that relates to the &quot;task&quot; of running it.  Runtime Version Be extra careful of this, it cannot be changed after the fact and will limit the modules that will work with it to the runtime version you select (If that makes sense!).  Sign in to the Azure portal.Search for and Select Automation Accounts.On the Automation Accounts page, Select your Automation account from the list.From the Automation account, Select Runbooks under Process Automation to open the list of runbooks.Click Create a runbook and fill in the information below.Click Create to create the runbook.  ","version":null,"tagName":"h2"},{"title":"Install any Modules​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#install-any-modules","content":" Here we need to install any PowerShell modules we want to use with our Scripts; make sure they match the runtime of your Runbooks.  Sign in to the Azure portal.Search for and Select Automation Accounts.On the Automation Accounts page, Select your Automation account from the list.From the Automation account, Select Modules under Shared Resources.In here you can see a list of currently installed modules and you can add more by Clicking on the +Add a module button.  tip You may find that you have to search around a bit for the module that you do actually want and when you do find the module you want, search for the command that you want to use, sometimes the module name is right but, the command is missing!  ","version":null,"tagName":"h2"},{"title":"Test Script​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#test-script","content":" ","version":null,"tagName":"h2"},{"title":"Create the Script​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#create-the-script","content":" Navigate to your runbook.Click Edit at the top.Here you can enter your script.  Useful options on the left hand side to note:  CMDLETS, which you can use to find commands from the installed modules.ASSETS, which will show you the various resources available to your runbooks which are saved within your automation account resource.  ","version":null,"tagName":"h3"},{"title":"Test Script​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#test-script-1","content":" Once your done and ready to test.  Click on Test pane at the top.Click Start in the top left to being running the scrpt.  I found it really hard to get my head around how this works for some reason. So expect that this may take quite a few tries to get right.  Storage Account Keys Before you can use the script as a base, you'll need to store the storage account key as a variable in your Automation account. Open your Automation Account.Click on Variables under Shared Resources.Click Add a variable.Create a new string variable. See the script for how to reference these in your runbooks.  # Ensures you do not inherit an AzContext in your runbook Disable-AzContextAutosave -Scope Process | Out-Null #Storage Account Information $StorageACCKey = Get-AutomationVariable -Name 'stgacckey01' $ContainerName = &quot;Enter the blob container name&quot; # Connect using a Managed Service Identity try { Connect-AzAccount -Identity } catch{ Write-Output &quot;Unable to login. Aborting.&quot;; exit } $Users = Get-AzADUser | Select-Object DisplayName, Id, Mail, UserPrincipalName Write-Output $Users # Exports the data in the $Users variable into a local environmental variable that will store the information whilst running in the Automation account. $Users | Export-Csv &quot;$Env:temp\\Users.csv&quot; -notypeinformation # Creates a new context to enable connection to the storage account. $Context = New-AzureStorageContext -StorageAccountName &quot;whautomationfiledump&quot; -StorageAccountKey $StorageACCKey # This copes the csv file in the $Env:temp/MFAState.csv variable and copies it to the blob. Set-AzureStorageBlobContent -Context $Context -Container $ContainerName -File &quot;$Env:temp\\Users.csv&quot; -Blob &quot;Users.csv&quot; -force   In my experience The test window is not like a command promtp and will not output the commands running or anything at all apart from really confusing errors. Try to build error catching into your script, use the try, catch commands to write the errors to the promtp for debugging. More in this in the testing section at the bottom.  ","version":null,"tagName":"h3"},{"title":"Setup the Schedule​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#setup-the-schedule","content":" This has been mostly regurgitated from this Microsoft link here.  From your Automation account, on the left-hand pane Select Schedules under Shared Resources.Select Add a schedule.Select whether the schedule runs once or on a reoccurring schedule by Selecting Once or Recurring. If you Select Once, specify a start time and then Select Create.If you Select Recurring, specify a start time. For Recur every, Select how often you want the runbook to repeat. Select by hour, day, week, or month. Press Create to complete.  tip You must publish the runbook before you can assign the schedule to it.  Head back to your Runbook.Select Link to scheduleat the top.Click the option to Link a schedule to your runbook, Select the schedule you created from the list.Click OK to complete.  ","version":null,"tagName":"h2"},{"title":"Testing​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#testing","content":" ","version":null,"tagName":"h2"},{"title":"Testing the script​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#testing-the-script","content":" Error handling​  The test pane window for the most part will not output useful errors or show you how the script is running. I'd suggest building error handling and status updates into your script if you wish during debugging, it will help immensely.  An example of the try, catch command sytax is below.  # Connect using a Managed Service Identity try { Connect-AzAccount -Identity } catch{ Write-Output &quot;Unable to login. Aborting.&quot;; exit }   I'd also suggest using write-output all over the place to confirm progress and variables etc.  Shout out Shout out to the VS code module for Automation Accounts, it'll let you pull down the runbook contents and edit in VsCode and upload it again. Highly recommend using this.  ","version":null,"tagName":"h3"},{"title":"Confirm the data export​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#confirm-the-data-export","content":" Navigate to your storage account.Click on the File shares or Containers option, wherever you saved your data to.Click into the share\\container, find your file and Click on the 3 dots to the right of it.Click View\\edit, it should display a basic output of the file.  ","version":null,"tagName":"h3"},{"title":"Further notes​","type":1,"pageTitle":"Automate Scripts in Azure","url":"/blog/Automate-scripts-in-Azure#further-notes","content":" Run As accounts are being deprecated, this method is by far the easiest to use when trying to pull info from AzureAD and Office 365. ","version":null,"tagName":"h2"},{"title":"Microsoft Defender for Endpoint Woes","type":0,"sectionRef":"#","url":"/blog/Defender-for-Endpoint-Woes","content":"","keywords":"","version":null},{"title":"The Investigation​","type":1,"pageTitle":"Microsoft Defender for Endpoint Woes","url":"/blog/Defender-for-Endpoint-Woes#the-investigation","content":" From checking the alert, I could see the service was stopping and starting but, no real reason as to why it was doing this. This is when I turned to PowerShell (still unsure of why I did this over trusty Event Viewer, just seems to be my default now).  Quickly smashed out the below command to see what I could find.  This promptly spat out these errors.  After googling this (as any techy would), there are a lot of mentions of this error message all over the place with suggestions to do the following:-  Disable or uninstall any other AV products on the device. Run a Full system scan for viruses. Run a System File Checker scan from the command line, sfc /scannow. Re-install the Defender for Endpoint on that device. Update the OS to a new version (A bit extreme mind you however, new OS versions have much better support for Defender, you don't need this service on Server 2016 and above, so it's still valid!)  ","version":null,"tagName":"h2"},{"title":"What Solved It​","type":1,"pageTitle":"Microsoft Defender for Endpoint Woes","url":"/blog/Defender-for-Endpoint-Woes#what-solved-it","content":" The short answer is, I'm not 100% certain.  Our first port of call was to remove the System Center Endpoint Protection application, which we probably should have done before installing the Defender for Endpoint application to be honest.  Secondly, we off-boarded the appliance from Defedner and then on-boarded it again by doing the following: -  Download the off-boarding script from your Defender portal. In the navigation pane, select Settings &gt; Endpoints &gt; Device management &gt; Offboarding. Off-Board the Server using the script provided by Microsoft below. C:\\Packages\\Plugins\\Microsoft.Azure.AzureDefenderForServers.MDE.Windows\\versionNo\\Install.ps1. The command is, Install.ps1 -OffboardingScript .\\WindowsDefenderATPOffboardingScript_valid_until_*.cmd Reboot the server. Check the Defender application is gone from Programs and Features and that the Services are gone. If not, manually uninstall using Programs and Features. On-Board the server again using the script provided by Microsoft. Command below. C:\\Packages\\Plugins\\Microsoft.Azure.AzureDefenderForServers.MDE.Windows\\versionNo\\Install.ps1. The command is, .\\Install.ps1 -OnboardingScript .\\WindowsDefenderATPOnboardingScript_valid_until_*.cmd Reboot the server.  Hopefully this helps somone! ","version":null,"tagName":"h2"},{"title":"Azure ligthhouse Setup","type":0,"sectionRef":"#","url":"/blog/Setup-Azure-Lighthouse","content":"","keywords":"","version":null},{"title":"Online Reading​","type":1,"pageTitle":"Azure ligthhouse Setup","url":"/blog/Setup-Azure-Lighthouse#online-reading","content":" Below are some links that are good reading before you dig into setting up the application.  Microsoft doc - What is Azure Lighthouse?.Microsoft doc - Onboard a customer to Azure Lighthouse.  ","version":null,"tagName":"h2"},{"title":"Setup Guidance​","type":1,"pageTitle":"Azure ligthhouse Setup","url":"/blog/Setup-Azure-Lighthouse#setup-guidance","content":" You've got some key areas to think about here before you get started, Azure AD and your Azure Lighthouse offering/delegation. Before you get cracking think about the following:  These are all explained further down!  Azure Active Directory:  Are you going to create seperate groups per department.What is your naming convention going to be.  Azure Lighthouse offering/delegation:  Offering Naming Convention (Client will see this).Offering Description (Client will see this).Authorisations.Delegation Scopes (Subscription level or Resource Group Leve.)  My Opinions I'd highly recommend reviewing the links mentioned in the Online Reading section for up to date information. The information following this point are from my notes.  ","version":null,"tagName":"h2"},{"title":"Azure AD​","type":1,"pageTitle":"Azure ligthhouse Setup","url":"/blog/Setup-Azure-Lighthouse#azure-ad","content":" To set things up, start by creating some groups within Azure AD. These groups will include the satff members who need access to the customer/client through Azure lighthouse. You have the flexibility to make these groups as detailed and numerous as needed.  I recommend considering two key roles, these roles can be fine-tuned to meet your specific requirements:  Azure Lighthouse ContributorAzure Lighthouse Reader  Role Assignment to staff business roles. Initially, I attempted to set up separate groups for each department, such as Operations, Service Desk, and Finance. While this approach worked well for the technical teams, it didn't meet my expectations when it came to granting access to billing information for the Finance team. After extensive testing, I discovered that using direct or named accounts, or leveraging the Microsoft Partner Center, provided a more effective solution.  ","version":null,"tagName":"h3"},{"title":"Azure Lighthouse Offering​","type":1,"pageTitle":"Azure ligthhouse Setup","url":"/blog/Setup-Azure-Lighthouse#azure-lighthouse-offering","content":" ARM Template​  Below is an outline and suggestion for each relevant configurable options for the ARM template.  On-boarding multiple Subscriptions or Resource Groups for one client\\customer. You have the option to delegate multiple resource groups and subscriptions all at once from the Service Providers dashboard within the customer's tenant. While the documentation might imply otherwise, it is indeed possible and functional.  Offering Name​  When naming your offering, remember that it will be visible in your customer's tenant, so it's important that it looks good. I recommend using a format like this:  Managing Company Name Lighthouse Offering for Customer Name - Subscription or Resource Group Name.  Be sure to replace the placeholders with the relevant details based on your naming convention.  Description(s)​  The description is customer-facing, so it should be clear and informative. Here's a suggested format:  Managing Company Name managed services offer for overseeing supported resources.Managing Company Name offer for managing and overseeing project resources for project or PO number.  Delegation Scope(s)​  You have two options: Subscription and Resource Group. These choices are quite self-explanatory. However, it's important to note that you cannot change these after deployment, so be sure to select the one that suits your specific needs.  Authorisations​  Authorisations represent the roles you intend to assign to your pre-configured Azure AD groups. You have the flexibility to define these roles as either broad or specific, although I recommend a broader approach to minimize the need for creating or updating new delegations in the future.  Broader Authorisations While this approach may sound appealing in theory, it's crucial to think about security. It may not be advisable if you are responsible for managing a small portion or a specific resource within your customer's environment. Additionally, consider the nature of your customer in this context.  Principal type: GroupName: Choose one of the mentioned groups in the section above.Display Name: Please do not edit. (This is the friendly name displayed in the customer's tenant, and it will default to the group name.)Role: Assign the roles as indicated for the groups listed above.Access Type: Permanent.  ","version":null,"tagName":"h3"},{"title":"ARM template Example​","type":1,"pageTitle":"Azure ligthhouse Setup","url":"/blog/Setup-Azure-Lighthouse#arm-template-example","content":" You can skip the initial lines until you locate mspOfferName. In the vicinity of this, you'll find the description field. To make changes, modify the defaultValue: data, not the description: information.  Confirming your scope Locate the line &quot;$schema&quot;: &quot;https://schema.management.azure.com/schemas/2019-08-01/subscriptionDeploymentTemplate.json#&quot;, and modify it to reflect either a subscription or resource deployment template, depending on your initial selection.  Similar situation with the mspOfferDescription: as well.  &quot;mspOfferName&quot;: { &quot;type&quot;: &quot;string&quot;, &quot;metadata&quot;: { &quot;description&quot;: &quot;Specify a unique name for your offer&quot; }, &quot;defaultValue&quot;: &quot;My Company Lighthouse Contributor Offer for Customer Name - Subscription Name &quot; }, &quot;mspOfferDescription&quot;: { &quot;type&quot;: &quot;string&quot;, &quot;metadata&quot;: { &quot;description&quot;: &quot;Name of the Managed Service Provider offering&quot; }, &quot;defaultValue&quot;: &quot;My Company managed services offer to administer support resources.&quot; }   Locate the variables: section to define your group and the Azure role assignments.  managedByTenantId&quot; - is your tenant or partner tenant ID.&quot;authorizations&quot;: - Are you Azure Roles assignments.&quot;principalId&quot; - Is your object in the managing tenant.&quot;roleDefinitionId&quot; - Is the Azure AD role you've assigned. In the case below, it's Contributor and the Managed Services Registration assignment Delete roles.&quot;principalIdDisplayName&quot; - Is your friendly Group name, this will show in your customer tenant, it does not need to match the group name in the managing tenant.  You'll see some of the information repeated for each role you assign to the same object in the managing tenant.  &quot;variables&quot;: { &quot;mspRegistrationName&quot;: &quot;[guid(parameters('mspOfferName'))]&quot;, &quot;mspAssignmentName&quot;: &quot;[guid(parameters('mspOfferName'))]&quot;, &quot;managedByTenantId&quot;: &quot;Your tenant ID&quot;, &quot;authorizations&quot;: [ { &quot;principalId&quot;: &quot;Your object in the managing tenant&quot;, &quot;roleDefinitionId&quot;: &quot;Id-number-here&quot;, &quot;principalIdDisplayName&quot;: &quot;Lighthouse Contributor&quot; }, { &quot;principalId&quot;: &quot;Your object in the managing tenant&quot;, &quot;roleDefinitionId&quot;: &quot;Id-number-here&quot;, &quot;principalIdDisplayName&quot;: &quot;Lighthouse Contributor&quot; } ] },   You can edit the JSON template directly! You don't need to always duck back into Azure Lighthouse to create the templates, you can just edit the JSON files if you're comfortable doing so.  ","version":null,"tagName":"h3"},{"title":"Using Lighthouse​","type":1,"pageTitle":"Azure ligthhouse Setup","url":"/blog/Setup-Azure-Lighthouse#using-lighthouse","content":" After setting up and assigning your Lighthouse delegations to your staff, there's no specific action required to access Azure Lighthouse. It's consistently available. Below, we provide two methods to verify the status of your delegations.  ","version":null,"tagName":"h2"},{"title":"Via the Lighthouse blade​","type":1,"pageTitle":"Azure ligthhouse Setup","url":"/blog/Setup-Azure-Lighthouse#via-the-lighthouse-blade","content":" Open the Azure Management Portal.Search for Azure Lighthouse.Click on the Delegations option on the left-hand side, you may need to click manage my customers if you’ve no connections.You will then see your list of your customer’s subscriptions that you have access to.  ","version":null,"tagName":"h3"},{"title":"Via the subscriptions blade​","type":1,"pageTitle":"Azure ligthhouse Setup","url":"/blog/Setup-Azure-Lighthouse#via-the-subscriptions-blade","content":" You'll need to show the customer in the subscription filter first though.  Open the Azure Management Portal.Navigate to the Subscriptions blade.The list of subscriptions will also list the customer subscriptions you have access too.In the Azure portal, Select the Directory + subscriptions or Settings icon in the top right of the page.In the Directories + subscriptions settings page, ensure that the Advanced filters toggle is turned off.In the Default subscription filter section, select the appropriate directory and subscription.  info If you have been granted access to one or more resource groups, rather than to an entire subscription, select the subscription to which that resource group belongs. You'll then work in the context of that subscription, but will only be able to access the designated resource group(s).  ","version":null,"tagName":"h3"},{"title":"Partner Earned Credit (PEC) using PAL​","type":1,"pageTitle":"Azure ligthhouse Setup","url":"/blog/Setup-Azure-Lighthouse#partner-earned-credit-pec-using-pal","content":" PAL (Partner Admin Link) is how a partner can be recognized by Microsoft for their work in Azure on-behalf-of their customer.  Microsoft doc - Associate your partner ID when you onboard new customers vai Lighthouse.Microsoft doc - Link a PartnerID with PAL or DPOR for PAL  To do this via Lighthouse, in a nutshell.  Create a service principal user account in your managing tenant.Using that service principal account, link to your Associated Partner ID in your managing tenant.Include at least one authorization which includes the service principal Account as a user with an Azure built-in role that is eligible for PEC.  caution This role must be granted as a permanent assignment, not as a just-in-time eligible authorization, in order for PEC to apply. ","version":null,"tagName":"h2"},{"title":"Request Certificate from internal CA","type":0,"sectionRef":"#","url":"/docs/Certificates/Request_a_Certificate_from_internal_CA","content":"","keywords":"","version":"0.1"},{"title":"Generating a CSR​","type":1,"pageTitle":"Request Certificate from internal CA","url":"/docs/Certificates/Request_a_Certificate_from_internal_CA#generating-a-csr","content":" Generate a CSR from another server, doing this from IIS is a tried and tested method.  ","version":"0.1","tagName":"h2"},{"title":"Submitting the request to the CA​","type":1,"pageTitle":"Request Certificate from internal CA","url":"/docs/Certificates/Request_a_Certificate_from_internal_CA#submitting-the-request-to-the-ca","content":" Open a web browser.Browse to your Certificate Authority website.  Certificate Authority website URL Enter the address of your CA followed by /certsrv for example http://ca server name/certsrv in the Address bar.  Click Request a Certificate.    Click submit an advanced certificate request.    Paste in the CSR.    Certificate template Make sure to change the template you want to use if that is applicable.    ","version":"0.1","tagName":"h2"},{"title":"Completing the Request​","type":1,"pageTitle":"Request Certificate from internal CA","url":"/docs/Certificates/Request_a_Certificate_from_internal_CA#completing-the-request","content":" Your certificate should be approved almost instantly and some download options will appear. Select whatever download option is best for you; I'd suggest renaming the certificate file you download, it'll have a generic name otherwise.  tip The chain option downloads the Certificate Authority certs (Root and Sub-CAs in the chain) as well, all the way back to the root ca. ","version":"0.1","tagName":"h2"},{"title":"Formats and Conversions","type":0,"sectionRef":"#","url":"/docs/Certificates/Formats_and_Conversions","content":"","keywords":"","version":"0.1"},{"title":"Certificate Formats​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#certificate-formats","content":" All you need to know is that there are several file extension types and encoding formats. Plus, in order to successfully install an SSL on your server, you need to know which type exactly your server or device requires.  ","version":"0.1","tagName":"h2"},{"title":"X.509 certificate encoding formats and extensions​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#x509-certificate-encoding-formats-and-extensions","content":" .pem, *.crt, *.ca-bundle, *.cer, *.p7b, *.p7s files contain one or more X.509 digital certificate files that use base64 (ASCII) encoding. You get one of those in a zip file.  You may also encounter *.pfx files. This is an archive file format for storing several cryptographic objects in a single file. In the scope of SSL certificates for SSL/TLS client and SSL/TLS web server authentication, a .pfx file must contain the end-entity certificate (issued for your domain), a matching private key, and may optionally include an intermediate certification authority (a.k.a. a CA Bundle). All this is wrapped up in a single file which is then protected with a pfx password. A Private key must be kept secret and is something that you generate alongside with the certificate signing request (CSR) by using an available tool.  ","version":"0.1","tagName":"h3"},{"title":"PEM (Base64 (ASCII))​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#pem-base64-ascii","content":" A PEM file is a text format, the pem file contains the certificates inforamtion in a Hash format, which can be placed into an application.  .pem.crt.ca-bundle  You can decode the Hash using a tool such as this online one, paste the text into the tool for it to show you the information. https://www.sslshopper.com/certificate-decoder.html    You can also do this using OpenSSL from your computer with the command openssl x509 -in certificate.crt -text -noout  ","version":"0.1","tagName":"h3"},{"title":"PKCS#7 (Base64 (ASCII))​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#pkcs7-base64-ascii","content":" Are mostly used in Windows or Java-based server environments (e.g. Internet Information Server (IIS), MS Exchange server, Java Tomcat, etc). PKCS#7 certificate file includes the end-entity certificate (the one issued to your domain name), plus one or more trusted intermediate certification authority files.  .p7b.p7s  ","version":"0.1","tagName":"h3"},{"title":"DER (Binary)​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#der-binary","content":" .der.cer  These files are very often used for Microsoft IIS services.  ","version":"0.1","tagName":"h3"},{"title":"PKCS#12 (Binary)​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#pkcs12-binary","content":" .pfx.p12  ","version":"0.1","tagName":"h3"},{"title":"Convertion to different formats​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#convertion-to-different-formats","content":" ","version":"0.1","tagName":"h2"},{"title":"Open SSL​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#open-ssl","content":" ","version":"0.1","tagName":"h3"},{"title":"Installing Open SSL​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#installing-open-ssl","content":" Install Chocolatey (Package Manager), Link to document .  ","version":"0.1","tagName":"h3"},{"title":"Using Open SSL​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#using-open-ssl","content":" ","version":"0.1","tagName":"h3"},{"title":"Before you begin​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#before-you-begin","content":" Create a folder and place the pfx file into the folder.To load openssl, open cmd as admin, navigate to “C:\\Program Files\\OpenSSL-Win64”, run the start.bat file to launch openssl.Change to the folder containing the pfx file and run the following commands.  ","version":"0.1","tagName":"h3"},{"title":"PFX file with separate key file​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#pfx-file-with-separate-key-file","content":" Follow the guidance in the above section before proceeding.  Type the following commands into your admin command prompt.  openssl pkcs12 -in nameofyourcertificate.pfx -nocerts -nodes -out privatekey.key openssl pkcs12 -in nameofyourcertificate.pfx -clcerts -nokeys -out certificate.cer  This will create a privatekey.key file (containing the private keys) and certificate.cer (containing the certificate).  ","version":"0.1","tagName":"h3"},{"title":"PFX to PEM with Private Key File​","type":1,"pageTitle":"Formats and Conversions","url":"/docs/Certificates/Formats_and_Conversions#pfx-to-pem-with-private-key-file","content":" Stack OverFlow link.  Follow the guidance in the Before you begin section above before proceeding.  To convert a PFX file to a PEM file that contains both the certificate and private key (you'll need the private key for the PFX file to do this).  openssl pkcs12 -in filename.pfx -out cert.pem -nodes  To convert a PFX file to separate public and private key PEM files (you'll need the private key for the PFX file to do this):  Extracts the private key form a PFX to a PEM file:  openssl pkcs12 -in filename.pfx -nocerts -out key.pem  Exports the certificate (includes the public key only):  openssl pkcs12 -in filename.pfx -clcerts -nokeys -out cert.pem  Removes the password (paraphrase) from the extracted private key (optional):  openssl rsa -in key.pem -out server.key ","version":"0.1","tagName":"h3"},{"title":"Welcome to the Wiki","type":0,"sectionRef":"#","url":"/docs/intro","content":"","keywords":"","version":"0.1"},{"title":"Navigating the Wiki​","type":1,"pageTitle":"Welcome to the Wiki","url":"/docs/intro#navigating-the-wiki","content":" Navigate using the navbar on the left hand side.  Search the site. There is a search bar in the top right, try searching keywords for what you're after.  ","version":"0.1","tagName":"h2"},{"title":"How the site works​","type":1,"pageTitle":"Welcome to the Wiki","url":"/docs/intro#how-the-site-works","content":" The website is stored within a GitHub Repo, this is then copied over to a Static Web App hosted in Azure using a GitHub action.The site is generated using Docusaurus, big shout to them for making this incredible beast! ","version":"0.1","tagName":"h2"},{"title":"Welcome to the Wiki","type":0,"sectionRef":"#","url":"/docs/next/intro","content":"","keywords":"","version":"Next"},{"title":"Navigating the Wiki​","type":1,"pageTitle":"Welcome to the Wiki","url":"/docs/next/intro#navigating-the-wiki","content":" Navigate using the navbar on the left hand side.  Search the site. There is a search bar in the top right, try searching keywords for what you're after.  ","version":"Next","tagName":"h2"},{"title":"How the site works​","type":1,"pageTitle":"Welcome to the Wiki","url":"/docs/next/intro#how-the-site-works","content":" The website is stored within a GitHub Repo, this is then copied over to a Static Web App hosted in Azure using a GitHub action.The site is generated using Docusaurus, big shout to them for making this incredible beast! ","version":"Next","tagName":"h2"},{"title":"Generating CSRs","type":0,"sectionRef":"#","url":"/docs/Certificates/Generating CSRs","content":"","keywords":"","version":"0.1"},{"title":"What is a CSR?​","type":1,"pageTitle":"Generating CSRs","url":"/docs/Certificates/Generating CSRs#what-is-a-csr","content":" What does it stand for? CSR stands for Certificate signing request.  The CSR contains information (e.g. common name, organization, country) the Certificate Authority (CA) will use to create your certificate. It also contains the public key that will be included in your certificate and is signed with the corresponding private key.  ","version":"0.1","tagName":"h2"},{"title":"Creating one (Windows IIS)​","type":1,"pageTitle":"Generating CSRs","url":"/docs/Certificates/Generating CSRs#creating-one-windows-iis","content":" The most common method of generating or creating a CSR is via Internet Information Services (IIS), which is a microsoft product that runs on the Windows OS as part of a server installation.  What other methods are there? There are lots of different methods to generate a CSR file, it depends on what operation system you're running. Try this link for more information.  Access the Server: Remote Desktop (RDP) or log in to a Windows machine running IIS.Open IIS: To open the Internet Information Services (IIS) Manager, simply type &quot;IIS&quot; in the Windows start menu search bar and click on the app when it appears.Select the Server: Inside the IIS Manager, locate and click on the Server Name corresponding to your IIS instance.Manage Certificates: In the center menu, navigate to the Security section and double-click on Server Certificates.Create Certificate Request: Within the Server Certificates window, go to the Actions menu on the right and select Create Certificate Request.Complete Certificate Request: The Request Certificate Wizard will appear. You will be prompted to enter specific information in the Distinguished Name Properties window. Fill in the required details as instructed.Proceed: After entering the necessary information, click Next to continue the certificate request process.  Mandatory information You must fill the Common Name in with the domain that you wish to cover with the certificate. If you wanted to create a certificate for &quot;www.finepies.com&quot;, that is what must be in the Common Name field.  In the Cryptographic Service Provider Properties window leave the top field as Microsoft RSA SChannel Cryptographic Provider.Make sure the minimum Bit length is set ot 2048 or higher.Click Next.Save the text file someone easy to find and you're done.  Take the CSR file to your certificate authority, internal or externally hosted and upload your CSR, you'll get a certificate back again.  ","version":"0.1","tagName":"h2"},{"title":"Final steps​","type":1,"pageTitle":"Generating CSRs","url":"/docs/Certificates/Generating CSRs#final-steps","content":" Depending on what you want to use the certificate for, you may need to &quot;complete&quot; the certificate.  Access IIS again.From the center menu double-click Server Certificates in the Security section.Click Complete Certificate Request.Complete the Wizard and it will have imported the certificate into the store you selected.  You'll now be able to export the certificate and the private key should you need to. ","version":"0.1","tagName":"h2"},{"title":"Decom an Azure AD App","type":0,"sectionRef":"#","url":"/docs/Microsoft Entra/Applications/Decom an Azure AD App","content":"","keywords":"","version":"0.1"},{"title":"Prerequisites​","type":1,"pageTitle":"Decom an Azure AD App","url":"/docs/Microsoft Entra/Applications/Decom an Azure AD App#prerequisites","content":" Must be an owner of the application or have admin privileges.  ","version":"0.1","tagName":"h2"},{"title":"Locate the App​","type":1,"pageTitle":"Decom an Azure AD App","url":"/docs/Microsoft Entra/Applications/Decom an Azure AD App#locate-the-app","content":" Sign in to the Azure portal.Search and select the Azure Active Directory app.Under Manage, select App registrations and select the application(Desktop Portal) that you want to configure.  ","version":"0.1","tagName":"h2"},{"title":"Confirm the App is not longer used​","type":1,"pageTitle":"Decom an Azure AD App","url":"/docs/Microsoft Entra/Applications/Decom an Azure AD App#confirm-the-app-is-not-longer-used","content":" Prevent access via the app to determine it is not being used, change the following Application settings using the Azure AD portal.  Overview Page  Enabled for users to sign-in? - Set this setting to NO. With this off, the application cannot be used.  Users and Groups Page  Remove all groups\\users (Screenshot them incase they need to be re-added).  Permissions Page  Remove all Admin and User consented permissions (Screenshot them incase they need to be re-added).  ","version":"0.1","tagName":"h2"},{"title":"Delete the App from Azure AD​","type":1,"pageTitle":"Decom an Azure AD App","url":"/docs/Microsoft Entra/Applications/Decom an Azure AD App#delete-the-app-from-azure-ad","content":" From the Overview page, select Delete.Read the deletion consequences. Check the box if one appears at the bottom of the pane.Select Delete to confirm that you want to delete the app. ","version":"0.1","tagName":"h2"},{"title":"Useful Conditional Access Policies","type":0,"sectionRef":"#","url":"/docs/Microsoft Entra/Conditional Access/Useful Conditional Access Policies","content":"","keywords":"","version":"0.1"},{"title":"Require a Compliant Windows Device​","type":1,"pageTitle":"Useful Conditional Access Policies","url":"/docs/Microsoft Entra/Conditional Access/Useful Conditional Access Policies#require-a-compliant-windows-device","content":" This policy will require the user to login\\access tenant resources from a device that is policy compliant with your organisation.  Assignments:  Users: Include: All Users (Preferably target a group that has all users using Intune.) Target Resources: Include: All Cloud Apps.Exclude: Intune and Intune Enrolment. Conditions: Device Platforms: Windows (as an example)Locations: Include: All Locations.Exclude: Office Locations (for example). Access Controls: Grant: Device to be compliant (Select require one control.)    ","version":"0.1","tagName":"h2"},{"title":"Require MFA for Admins​","type":1,"pageTitle":"Useful Conditional Access Policies","url":"/docs/Microsoft Entra/Conditional Access/Useful Conditional Access Policies#require-mfa-for-admins","content":" Admin accounts are often targeted for attacks so enforcing MFA is a good idea.  Assignments:  Select Users or workload identities. Include: Directory Roles or User accounts depending on the above selection.Exclude: Any break glass accounts. Target Resources: Include: All Cloud Apps. Conditions: None Access Controls: Grant access, Require multifactor authentication.   ","version":"0.1","tagName":"h2"},{"title":"Network Security Groups","type":0,"sectionRef":"#","url":"/docs/Microsoft Azure/Networking/Network Security Groups","content":"","keywords":"","version":"0.1"},{"title":"Rules and Priorities​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#rules-and-priorities","content":" ","version":"0.1","tagName":"h2"},{"title":"Service Tags​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#service-tags","content":" Virtual Network Service tags | Microsoft doc link  A service tag represents a group of IP address prefixes from a given Azure service. Microsoft manages the address prefixes encompassed by the service tag and automatically updates the service tag as addresses change, minimizing the complexity of frequent updates to network security rules.  ","version":"0.1","tagName":"h3"},{"title":"Rule Priority​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#rule-priority","content":" A number between 100 and 4096. Rules are processed in priority order, with lower numbers processed before higher numbers, because lower numbers have higher priority. Once traffic matches a rule, processing stops. As a result, any rules that exist with lower priorities (higher numbers) that have the same attributes as rules with higher priorities aren’t processed.  ","version":"0.1","tagName":"h3"},{"title":"Inbound Rule Suggestions​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#inbound-rule-suggestions","content":" Inbound 100 to 109​  Priority\tName\tPort\tProtocol\tSource\tDestination\tAction\tNotes100 to 109 100 to 109 available for overrides   Inbound 110 to 199​  Priority\tName\tPort\tProtocol\tSource\tDestination\tAction\tNotes200\tDeny-Internet-to-Any\tAny\tAny\tInternet (Service tag)\tAny\tDeny\tDeny All inbound Internet access. 200 to 299\tAllow any internal vNet services\t-\t-\t-\t-\t-\tAllow any internal vNet services  Inbound 300​  Priority\tName\tPort\tProtocol\tSource\tDestination\tAction\tNotes300\tDeny-From-VNET-to-VNET\tAny\tAny\tAny\tAny\tDeny\t-  Inbound 301 to 64999​  Priority\tName\tPort\tProtocol\tSource\tDestination\tAction\tNotes301 to 64999\tFor non-vnet or internet facing rules\t-\t-\t-\t-\t-\tFor non-vnet or internet facing rules  Inbound 65000 to 65500​  Priority\tName\tPort\tProtocol\tSource\tDestination\tAction\tNotes65000\tAllowVnetInBound\tAny\tAny\tVirtualNetwork\tVirtualNetwork\tAllow\tBuilt in Rule 65000 to 65500\tAre built in rules\t-\t-\t-\t-\t-\tAre built in rules  Inbound 65500 to 65501​  Priority\tName\tPort\tProtocol\tSource\tDestination\tAction\tNotes65500\tAllowAzureLoadBalancerInBound\tAny\tAny\tAzureLoadBalancer\tAny\tAllow\tBuilt in Rule 65501\tDenyAllInBound\tAny\tAny\tAny\tAny\tDeny\tBuilt in Rule  ","version":"0.1","tagName":"h3"},{"title":"Outbound Rule Suggestings​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#outbound-rule-suggestings","content":" Outbound 100 to 109​  Priority\tName\tPort\tProtocol\tSource\tDestination\tAction\tNotes100 to 109 100 to 109 available for overrides   Outbound 110 to 199​  Priority\tName\tPort\tProtocol\tSource\tDestination\tAction\tNotes110 to 199\tAllow any inbound services Allow any inbound services 111\tAllow http\t80\tTCP\t-\tInternet (Sevice Tag)\tAllow\tAllow http services to internet 112\tAllow https\t443\tTCP\t-\tInternet (Service Tag)\tAllow\tAllow https services to internet 114\tAllow-DNS-to-MicrosoftAzure\t53\tAny\t-\t168.63.129.16\tAllow\tAllow DNS to Azure DNS IP 115\tAllow-AADConnect-to-AzureAD\t443,80\tTCP\t-\tAzureAzureActiveDirectory (Service Tag)\tAllow\tAllow Allow AAD Connect services. 116\tAllow-Azuresiterecovery\t443,80\tTCP\t-\tAzureSiteRecovery (Service Tag)\tAllow\tAllow Azure Site Recovery services. 117\tAllow-AzureKeyVault\t443,80\tTCP\t-\tAzureKeyVault (Service Tag)\tAllow\tAllow Azure Key Vault services. (Dependency for ASR). 118\tAllow-GuestAndHybridManagement\t443,80\tTCP\t-\tGuestAndHybridManagement (Sevice Tag)\tAllow\tAllow Guest and Hybrid Management services. (Dependency for ASR, AzMonitor). 119\tAllow-Storage\t443,80\tTCP\t-\tStorage (Service Tag)\tAllow\tAllow Storage services. (Dependency for ASR, AzMonitor). 120\tAllow-EventHub\t443,80\tTCP\t-\tEventhub (Service Tag)\tAllow\tAllow Event Hub services. (Dependency for ASR). 121\tAllow-AzureMonitor\t443,80\tTCP\t-\tAzureMonitor (Service Tag)\tAllow\tAllow Event Hub services. (Dependency for ASR). 122\tAllow-WindowsUpdate-AzUpdateDeliver\t443,80\tTCP\t-\tAzureUpdateDelivery (Service Tag)\tAllow\tAllow Az update delivery services. 123\tAllow-WindowsUpdate-AzFrontDoorFP\t443,80\tTCP\t-\tAzureFrontDoor.FirstParty (Service Tag)\tAllow\tAllow Az update delivery services.  ","version":"0.1","tagName":"h3"},{"title":"Flow Logs​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#flow-logs","content":" NSG flow logs is a feature of Azure Network Watcher that allows you to log information about IP traffic flowing through a network security group (NSG). Flow data is sent to Azure Storage from where you can access it and export it to any visualization tool.  Flow logs for network security groups | Microsoft doc link  ","version":"0.1","tagName":"h2"},{"title":"Common use cases​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#common-use-cases","content":" Sources All of the below information has been ripped out of a Microsoft doc, not my original material.  ","version":"0.1","tagName":"h3"},{"title":"Network monitoring​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#network-monitoring","content":" Identify unknown or undesired traffic.Monitor traffic levels and bandwidth consumption.Filter flow logs by IP and port to understand application behavior.Export flow logs to analytics and visualization tools of your choice to set up monitoring dashboards.  ","version":"0.1","tagName":"h3"},{"title":"Usage monitoring and optimization​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#usage-monitoring-and-optimization","content":" Identify top talkers in your network.Combine with GeoIP data to identify cross-region traffic.Understand traffic growth for capacity forecasting.Use data to remove overly restrictive traffic rules.  ","version":"0.1","tagName":"h3"},{"title":"Compliance​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#compliance","content":" Use flow data to verify network isolation and compliance with enterprise access rules.Network forensics and security analysisAnalyze network flows from compromised IPs and network interfaces.Export flow logs to any SIEM or IDS tool of your choice.  ","version":"0.1","tagName":"h3"},{"title":"Reading the flow log​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#reading-the-flow-log","content":" Logs are in JSON format and will be outputting in the json file format.The information that is interesting is in the flowtuples section of the json file.  ","version":"0.1","tagName":"h3"},{"title":"Example flow log entry​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#example-flow-log-entry","content":" { &quot;records&quot;: [ { &quot;time&quot;: &quot;2018-11-13T12:00:35.3899262Z&quot;, &quot;systemId&quot;: &quot;a0fca5ce-022c-47b1-9735-89943b42f2fa&quot;, &quot;category&quot;: &quot;NetworkSecurityGroupFlowEvent&quot;, &quot;resourceId&quot;: &quot;/SUBSCRIPTIONS/00000000-0000-0000-0000-000000000000/RESOURCEGROUPS/FABRIKAMRG/PROVIDERS/MICROSOFT.NETWORK/NETWORKSECURITYGROUPS/FABRIAKMVM1-NSG&quot;, &quot;operationName&quot;: &quot;NetworkSecurityGroupFlowEvents&quot;, &quot;properties&quot;: { &quot;Version&quot;: 2, &quot;flows&quot;: [ { &quot;rule&quot;: &quot;DefaultRule_DenyAllInBound&quot;, &quot;flows&quot;: [ { &quot;mac&quot;: &quot;000D3AF87856&quot;, &quot;flowTuples&quot;: [ &quot;1542110402,94.102.49.190,10.5.16.4,28746,443,U,I,D,B,,,,&quot;, &quot;1542110424,176.119.4.10,10.5.16.4,56509,59336,T,I,D,B,,,,&quot;, &quot;1542110432,167.99.86.8,10.5.16.4,48495,8088,T,I,D,B,,,,&quot; ] } ] }, { &quot;rule&quot;: &quot;DefaultRule_AllowInternetOutBound&quot;, &quot;flows&quot;: [ { &quot;mac&quot;: &quot;000D3AF87856&quot;, &quot;flowTuples&quot;: [ &quot;1542110377,10.5.16.4,13.67.143.118,59831,443,T,O,A,B,,,,&quot;, &quot;1542110379,10.5.16.4,13.67.143.117,59932,443,T,O,A,E,1,66,1,66&quot;, &quot;1542110379,10.5.16.4,13.67.143.115,44931,443,T,O,A,C,30,16978,24,14008&quot;, &quot;1542110406,10.5.16.4,40.71.12.225,59929,443,T,O,A,E,15,8489,12,7054&quot; ] } ] } ] } }, { &quot;time&quot;: &quot;2018-11-13T12:01:35.3918317Z&quot;, &quot;systemId&quot;: &quot;a0fca5ce-022c-47b1-9735-89943b42f2fa&quot;, &quot;category&quot;: &quot;NetworkSecurityGroupFlowEvent&quot;, &quot;resourceId&quot;: &quot;/SUBSCRIPTIONS/00000000-0000-0000-0000-000000000000/RESOURCEGROUPS/FABRIKAMRG/PROVIDERS/MICROSOFT.NETWORK/NETWORKSECURITYGROUPS/FABRIAKMVM1-NSG&quot;, &quot;operationName&quot;: &quot;NetworkSecurityGroupFlowEvents&quot;, &quot;properties&quot;: { &quot;Version&quot;: 2, &quot;flows&quot;: [ { &quot;rule&quot;: &quot;DefaultRule_DenyAllInBound&quot;, &quot;flows&quot;: [ { &quot;mac&quot;: &quot;000D3AF87856&quot;, &quot;flowTuples&quot;: [ &quot;1542110437,125.64.94.197,10.5.16.4,59752,18264,T,I,D,B,,,,&quot;, &quot;1542110475,80.211.72.221,10.5.16.4,37433,8088,T,I,D,B,,,,&quot;, &quot;1542110487,46.101.199.124,10.5.16.4,60577,8088,T,I,D,B,,,,&quot;, &quot;1542110490,176.119.4.30,10.5.16.4,57067,52801,T,I,D,B,,,,&quot; ] } ] } ] } }   ","version":"0.1","tagName":"h3"},{"title":"Flow Tuples​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#flow-tuples","content":" flowTuples: String that contains multiple properties for the flow tuple in a comma-separated format  Example entry: 1493695838,185.170.185.105,10.2.0.4,35370,23,T,I,A,C,1021,588096,8005,4610880    ","version":"0.1","tagName":"h3"},{"title":"Script to read the logs via PowerShell​","type":1,"pageTitle":"Network Security Groups","url":"/docs/Microsoft Azure/Networking/Network Security Groups#script-to-read-the-logs-via-powershell","content":" Dump the below into a file as a script (.ps1) filetype.  To use the script below, navigate to the location of the file, and use the NsgFlowLogFileName switch to select the JSON file.  cd C:\\Temp\\ .\\Parse-NSG-FlowLog_json.ps1 -NsgFlowLogFileName .\\PT1H.json | ft -AutoSize   info I didn't write this script, I cannot take any credit for it!  param( [string]$NsgFlowLogFileName = &quot;C:\\Temp\\filename.json&quot; ) # Import the logs from the file convert it from json into a powershell object $logs = gc $NsgFlowLogFileName -ErrorAction SilentlyContinue | ConvertFrom-Json | select -ExpandProperty records # Loop through each entry in the json file foreach ($Log in $Logs) { #Get a list of flows $Flows = $log.properties.flows # Loop through each flow of each json entry and output the details foreach ($Flow in $Flows) { # Split the flow information to a variable for easier and quicker referencing $FlowInfo = $Flow.flows.flowtuples[0] -split(',') # Output details as a powershell object [pscustomobject]@{ DateTime = (Get-Date 01.01.1970)+([System.TimeSpan]::fromseconds($FlowInfo[0])) NSGName = $Log.resourceId.split('/')[-1] RuleName = $Flow.ruleDecision = switch ($FlowInfo[7]) { 'a' { &quot;Allowed&quot; } ; &quot;d&quot; {&quot;Denied&quot;} } FlowState = switch ($FlowInfo[8]) { 'B' { &quot;Begin&quot; } ; &quot;C&quot; {&quot;Continue&quot;} ; &quot;e&quot; {&quot;End&quot;} } SourceIP = $FlowInfo[1] SourcePort = $FlowInfo[3] DestIP = $FlowInfo[2] DestPort = $FlowInfo[4] Protocol = switch ($FlowInfo[5]) { 't' { &quot;TCP&quot; } ; &quot;u&quot; {&quot;UDP&quot;} } Direction = switch ($FlowInfo[6]) { 'i' { &quot;InBound&quot; } ; &quot;o&quot; {&quot;OutBound&quot;} } SourcePackets = $FlowInfo[9] SourceBytes = $FlowInfo[10] DestPackets = $FlowInfo[11] DestBytes = $FlowInfo[12] # Below line ends the flow loop, then filters out the empty entries. } | where SourceIP -ne $null } }  ","version":"0.1","tagName":"h2"}],"options":{"id":"default"}}